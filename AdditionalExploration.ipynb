{"cells":[{"cell_type":"markdown","metadata":{"id":"b8tSEB4mnYqG"},"source":["### Data Preprocessing (See other Notebook for more details)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"EINO0dv7nVnf"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","idx=pd.IndexSlice\n","import time\n","import random\n","import matplotlib\n","#%matplotlib notebook\n","import matplotlib.pyplot as plt\n","import scipy.stats\n","#from pandas.plotting import autocorrelation_plot\n","import matplotlib.offsetbox as offsetbox\n","from matplotlib.ticker import StrMethodFormatter\n","import sklearn.linear_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y4C6nLTYnVnh"},"outputs":[],"source":["#for some reason, this needs to be in a separate cell\n","params={\n","    \"font.size\":15,\n","    \"lines.linewidth\":5\n","}\n","plt.rcParams.update(params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgSkKIlvnVni"},"outputs":[],"source":["### Do all the cleaning and preprocessing here (Copied from the other notebook)\n","### SKIP THIS IF YOU ALREADY HAVE THE PICKLED X AND Y FILES\n","\n","# Read in working_dataset.pkl\n","data = pd.read_pickle(\"working_dataset.pkl\")\n","\n","# Label Encoding Term and dropping YearTerm\n","from sklearn import preprocessing\n","  \n","# Label_encoder object knows how to understand word labels.\n","label_encoder = preprocessing.LabelEncoder()\n","df=data\n","\n","# Encode labels in column 'species'.\n","df['Term']= label_encoder.fit_transform(df['Term'])\n","df = df.drop('YearTerm', axis=1)\n","\n","#Creatinig a New Column CourseCode by combining Subject, Number and dropping the Course Title, Subject and Number Columns\n","df[\"CourseCode\"] = (data[\"Subject\"] + \" \" + df[\"Number\"].astype('str'))\n","df.drop(['Course Title','Subject','Number'],axis=1,inplace=True)\n","\n","## Need to Convert the Grades to a Overall Gpa Value\n","# First we will Drop the 'W' Column and define the Grades as well as their corresponding Weightage\n","df.drop(['W'],axis=1,inplace=True)\n","grades = ['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D', 'D-', 'F']\n","WEIGHT = [4.00, 4.00, 3.67, 3.33, 3, 2.67, 2.33, 2, 1.67, 1.33, 1, 0.67, 0]\n","df['GPA'] = df[grades].mul(WEIGHT).sum(1)/df[grades].sum(axis=1)\n","\n","# Drop the Grades Column since we do not really need it\n","df_new=df.drop(grades,axis=1)\n","\n","# Dropping all the rows with Null values\n","df_notna = df_new.dropna()\n","\n","# Group the data\n","df_final = df_notna.groupby(['Year','Term','Sched Type','Primary Instructor', 'CourseCode'])['GPA'].mean().reset_index()\n","\n","# Get one hot encoding of columns Sched Type\n","one_hot_encoded_data = pd.get_dummies(df_final, columns = ['Sched Type'])\n","\n","# Remove redundant date columns\n","one_hot_encoded_data['Year'] = one_hot_encoded_data['Year'].apply(lambda x: int(str(x)[-2:]))\n","\n","def calc_smooth_mean(df, by, on, m):\n","    # Compute the global mean\n","    mean = df[on].mean()\n","\n","    # Compute the number of values and the mean of each group\n","    agg = df.groupby(by)[on].agg(['count', 'mean'])\n","    counts = agg['count']\n","    means = agg['mean']\n","\n","    # Compute the \"smoothed\" means\n","    smooth = (counts * means + m * mean) / (counts + m)\n","\n","    # Replace each value by the according smoothed mean\n","    return df[by].map(smooth)\n","\n","one_hot_encoded_data['CourseCode'] = calc_smooth_mean(one_hot_encoded_data, by='CourseCode', on='GPA', m=10)\n","one_hot_encoded_data['Primary Instructor'] = calc_smooth_mean(one_hot_encoded_data, by='Primary Instructor', on='GPA', m=10)\n","\n","Y = one_hot_encoded_data['GPA'].round(2)\n","X = one_hot_encoded_data.drop('GPA',axis=1)\n","\n","# Save X and Y to a pickle file\n","X.to_pickle(\"X_Final.pkl\")\n","Y.to_pickle(\"Y_Final.pkl\")"]},{"cell_type":"markdown","metadata":{"id":"jMEQu7rjnqOv"},"source":["### Load Pickled Preprocessed X Y Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fe0cxMOpnx2F"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"NE5J_3vGnVnk"},"outputs":[],"source":["# Load preprocessed X and Y data\n","X = pd.read_pickle(\"X_Final.pkl\")\n","Y = pd.read_pickle(\"Y_Final.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5e35bIPdnVnl","outputId":"61fc09c6-e557-407c-9637-5ff32d9c430c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set size: 23188 \n"," Test set size: 7730 \n"," Validation set size: 7730\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=104, shuffle=True)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=104, shuffle=True) # 0.25 x 0.8 = 0.2\n","\n","print(\"Training set size:\", str(len(X_train)), \"\\n\", \"Test set size:\", str(len(X_test)), \"\\n\", \"Validation set size:\", str(len(X_val)))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Get Linear Regression Baseline"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean absolute error: 0.18\n","Mean squared error: 0.05\n","Root mean squared error: 0.23\n"]}],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test,y_train, y_test = train_test_split(X,Y ,\n","                                   random_state=104, \n","                                   test_size=0.25, \n","                                   shuffle=True)\n","\n","from sklearn.linear_model import LinearRegression\n","regressor = LinearRegression()\n","regressor.fit(X_train, y_train)\n","\n","y_pred = regressor.predict(X_test)\n","\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","mae = mean_absolute_error(y_test, y_pred)\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","\n","print(f'Mean absolute error: {mae:.2f}')\n","print(f'Mean squared error: {mse:.2f}')\n","print(f'Root mean squared error: {rmse:.2f}')"]},{"cell_type":"markdown","metadata":{"id":"HorfUh7vng-q"},"source":["# Building the Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"CkGWpkJjof0Y"},"source":["## Imports and Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtRGnXaPnVnl","outputId":"eca7bd76-f68e-4895-d84d-9477675d6884"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import average_precision_score, roc_auc_score\n","\n","print(torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    torch.cuda.set_device(0)\n","    torch.cuda.manual_seed_all(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJPZRTDDnVnm"},"outputs":[],"source":["class GPADataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = torch.tensor(X.values, dtype=torch.float32)\n","        self.y = torch.tensor(y.values, dtype=torch.float32)\n","        self.len = self.X.shape[0]\n","\n","    def __getitem__(self, index):\n","        return self.X[index], self.y[index]\n","\n","    def __len__(self):\n","        return self.len"]},{"cell_type":"markdown","metadata":{"id":"Yg5NatT-n2L1"},"source":["## Build a Shallow NN (2 Hidden Layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tX5TUeEQnVnn"},"outputs":[],"source":["class ShallowNetwork():\n","    def __init__(self, input_size, hidden1_size, hidden2_size, output_size, learning_rate, optimizer):\n","        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        self.input_size = input_size\n","        self.hidden1_size = hidden1_size\n","        self.hidden2_size = hidden2_size\n","        self.output_size = output_size\n","        self.learning_rate = learning_rate\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(self.input_size, self.hidden1_size),\n","            nn.ReLU(),\n","            nn.Dropout(0.4),\n","            nn.Linear(self.hidden1_size, self.hidden2_size),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(self.hidden2_size, self.output_size)\n","        )\n","        self.model.to(self.device)\n","\n","        self.loss_function = nn.MSELoss()\n","        if optimizer == \"Adam\":\n","          self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n","        elif optimizer == \"SGD\":\n","          self.optimizer = torch.optim.SGD(self.model.parameters(), lr = self.learning_rate, weight_decay=1e-4)\n","        elif optimizer == \"RMSprop\":\n","          self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n","\n","    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size):\n","        self.model.train()\n","        train_dataset = GPADataset(X_train, y_train)\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n","        val_dataset = GPADataset(X_val, y_val)\n","        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","        train_loss = []\n","        val_loss = []\n","        num_batches = len(X_train)/batch_size\n","        for epoch in range(epochs):\n","            for i, (X, y) in enumerate(train_loader):\n","                X = X.to(self.device)\n","                y = y.to(self.device)\n","                self.optimizer.zero_grad()\n","                y_pred = self.model(X)\n","                y_pred = y_pred.squeeze(-1)\n","                y = y.squeeze(-1)\n","                loss = self.loss_function(y_pred, y)\n","                loss.backward()\n","                self.optimizer.step()\n","                train_loss.append(loss.item())\n","\n","            # Validation\n","            with torch.no_grad():\n","                for i, (X, y) in enumerate(val_loader):\n","                    X = X.to(self.device)\n","                    y = y.to(self.device)\n","                    y_pred = self.model(X)\n","                    y_pred = y_pred.squeeze(-1)\n","                    y = y.squeeze(-1)\n","                    loss = self.loss_function(y_pred, y)\n","                    val_loss.append(loss.item())\n","\n","            # Only print every 10 epochs\n","            if epoch % 10 == 0:\n","                print(f\"{epoch}/{epochs} - Training Loss: {train_loss[-1]:.4f} Validation Loss: {val_loss[-1]:.4f}\")\n","\n","        return train_loss, val_loss\n","\n","    def predict(self, X_test):\n","        self.model.eval()\n","        with torch.no_grad():\n","            X_test = torch.tensor(X_test.values, dtype=torch.float32).to(self.device)\n","            output = self.model(X_test)\n","        return output.cpu().numpy()\n","\n","    def evaluate(self, X_test, y_test):\n","        self.model.eval()\n","        with torch.no_grad():\n","            X_test = torch.tensor(X_test.values, dtype=torch.float32).to(self.device)\n","            output = self.model(X_test)\n","            loss = self.loss_function(output, y_test)\n","        return loss\n","\n","    def save(self, path):\n","        torch.save(self.model.state_dict(), path)\n","\n","    def load(self, path):\n","        self.model.load_state_dict(torch.load(path))"]},{"cell_type":"markdown","metadata":{"id":"wy7mJzpun_11"},"source":["## Build a Deep NN (6 Hidden Layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMJMhBexnVno"},"outputs":[],"source":["class DeepNetwork():\n","    def __init__(self, input_size, hidden1_size, hidden2_size, hidden3_size, hidden4_size, hidden5_size, hidden6_size, output_size, learning_rate, optimizer):\n","        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        self.input_size = input_size\n","        self.hidden1_size = hidden1_size\n","        self.hidden2_size = hidden2_size\n","        self.hidden3_size = hidden3_size\n","        self.hidden4_size = hidden4_size\n","        self.hidden5_size = hidden5_size\n","        self.hidden6_size = hidden6_size\n","        self.output_size = output_size\n","        self.learning_rate = learning_rate\n","\n","        self.model = nn.Sequential(\n","            nn.Linear(self.input_size, self.hidden1_size),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(self.hidden1_size, self.hidden2_size),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(self.hidden2_size, self.hidden3_size),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(self.hidden3_size, self.hidden4_size),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(self.hidden4_size, self.hidden5_size),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(self.hidden5_size, self.hidden6_size),\n","            nn.ReLU(),\n","            nn.Dropout(0.2),\n","            nn.Linear(self.hidden6_size, self.output_size)\n","        )\n","        self.model.to(self.device)\n","\n","        self.loss_function = nn.MSELoss()\n","        if optimizer == \"Adam\":\n","          self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n","        elif optimizer == \"SGD\":\n","          self.optimizer = torch.optim.SGD(self.model.parameters(), lr = self.learning_rate, weight_decay=1e-4)\n","        elif optimizer == \"RMSprop\":\n","          self.optimizer = torch.optim.RMSprop(self.model.parameters(), lr=self.learning_rate, weight_decay=1e-4)\n","\n","    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size):\n","        self.model.train()\n","        train_dataset = GPADataset(X_train, y_train)\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n","        val_dataset = GPADataset(X_val, y_val)\n","        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","        train_loss = []\n","        val_loss = []\n","        num_batches = len(X_train)/batch_size\n","        for epoch in range(epochs):\n","            for i, (X, y) in enumerate(train_loader):\n","                X = X.to(self.device)\n","                y = y.to(self.device)\n","                self.optimizer.zero_grad()\n","                y_pred = self.model(X)\n","                y_pred = y_pred.squeeze(-1)\n","                y = y.squeeze(-1)\n","                loss = self.loss_function(y_pred, y)\n","                loss.backward()\n","                self.optimizer.step()\n","                train_loss.append(loss.item())\n","\n","            # Validation\n","            with torch.no_grad():\n","                for i, (X, y) in enumerate(val_loader):\n","                    X = X.to(self.device)\n","                    y = y.to(self.device)\n","                    y_pred = self.model(X)\n","                    y_pred = y_pred.squeeze(-1)\n","                    y = y.squeeze(-1)\n","                    loss = self.loss_function(y_pred, y)\n","                    val_loss.append(loss.item())\n","\n","            # Only print every 10 epochs\n","            if epoch % 10 == 0:\n","                print(f\"{epoch}/{epochs} - Training Loss: {train_loss[-1]:.4f} Validation Loss: {val_loss[-1]:.4f}\")\n","\n","        return train_loss, val_loss\n","\n","    def predict(self, X_test):\n","        self.model.eval()\n","        with torch.no_grad():\n","            X_test = torch.tensor(X_test.values, dtype=torch.float32).to(self.device)\n","            output = self.model(X_test)\n","        return output.cpu().numpy()\n","\n","    def evaluate(self, X_test, y_test):\n","        self.model.eval()\n","        with torch.no_grad():\n","            X_test = torch.tensor(X_test.values, dtype=torch.float32).to(self.device)\n","            output = self.model(X_test)\n","            loss = self.loss_function(output, y_test)\n","        return loss\n","\n","    def save(self, path):\n","        torch.save(self.model.state_dict(), path)\n","\n","    def load(self, path):\n","        self.model.load_state_dict(torch.load(path))"]},{"cell_type":"markdown","metadata":{"id":"LomE3aedoMGD"},"source":["# Construct and Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ey6EoeO8nVnp"},"outputs":[],"source":["### Set parameters for the modeltype, optimizer, learning rate, batch size, and epochs\n","#opt_types = [\"Adam\", \"SGD\", \"RMSprop\"]\n","mtype, opt, lr, bs, e = \"SN\", \"Adam\", .05, 1000, 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ifc6IUpqnVnp"},"outputs":[],"source":["### Change the variables in the cell above, do not manually change the code below ###\n","if (mtype == \"SN\"):\n","    net = ShallowNetwork(X_train.shape[1], 8, 4, 1, lr, opt)\n","elif (mtype == \"DN\"):\n","    net = DeepNetwork(X_train.shape[1], 32, 64, 128, 64, 32, 16, 1, lr, opt)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4AIM3_W1nVnq","outputId":"7c0c0c11-1957-4bd3-cb2b-6e30bbf9af83"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model not found, training...\n","0/100 - Training Loss: 11.3098 Validation Loss: 11.1158\n","10/100 - Training Loss: 3.0167 Validation Loss: 2.8824\n","20/100 - Training Loss: 1.5566 Validation Loss: 1.3666\n","30/100 - Training Loss: 0.9735 Validation Loss: 0.8731\n","40/100 - Training Loss: 0.6191 Validation Loss: 0.5157\n","50/100 - Training Loss: 0.3594 Validation Loss: 0.3276\n","60/100 - Training Loss: 0.2127 Validation Loss: 0.2280\n","70/100 - Training Loss: 0.1936 Validation Loss: 0.1790\n","80/100 - Training Loss: 0.1632 Validation Loss: 0.1549\n","90/100 - Training Loss: 0.1546 Validation Loss: 0.1474\n","Model Saved: ./models/SN_Adam_lr0.005_bs1000_e100.pth\n"]}],"source":["# Check if the model has been trained before\n","force_train = False\n","if (os.path.exists(f\"./models/{mtype}_{opt}_lr{lr}_bs{bs}_e{e}.pth\") and not force_train):\n","    print(\"Trained model with same parameters found, loading...\")\n","    net.load(f\"./models/{mtype}_{opt}_lr{lr}_bs{bs}_e{e}.pth\")\n","else:\n","    print(\"Model not found, training...\")\n","    train_losses, val_losses = net.train(X_train, y_train, X_val, y_val, e, bs)\n","    net.save(f\"./models/{mtype}_{opt}_lr{lr}_bs{bs}_e{e}.pth\")\n","    print(f\"Model Saved: ./models/{mtype}_{opt}_lr{lr}_bs{bs}_e{e}.pth\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W3iBDuf6nVnr"},"outputs":[],"source":["def Get_Scores(net, X_test, y_test):\n","    pred = net.predict(X_test)\n","    mae = np.mean(np.abs(pred - y_test.values))\n","    print(f\"Mean Absolute Error: {mae}\")\n","\n","    # Get mean squared error on the validation data\n","    mse = np.mean((pred - y_test.values)**2)\n","    print(f\"Mean Squared Error: {mse}\")\n","\n","    # get root mean squared error on the validation data\n","    rmse = np.sqrt(mse)\n","    print(f\"Root Mean Squared Error: {rmse}\")\n","\n","    return mae, mse, rmse\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dgyxbng0nVnr","outputId":"dad390da-e33a-4a26-f2bb-385232a42ba8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Absolute Error: 0.31466599384269534\n","Mean Squared Error: 0.1522082006778982\n","Root Mean Squared Error: 0.39013869415619135\n"]}],"source":["mae, mse, rmse = Get_Scores(net, X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A69GaHxcnVns"},"outputs":[],"source":["### Save the model parameters and scores to a csv file for later comparison\n","with open(\"model_scores.csv\", \"a\") as f:\n","    f.write(f\"{mtype},{opt},{lr},{bs},{e},{mae:.4f},{mse:.4f},{rmse:.4f}\\n\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"torch_cuda","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"7daffc5285a68314b8fdf3adcc576838549d2d570a48b97855924d6ca23bc0fa"}}},"nbformat":4,"nbformat_minor":0}
